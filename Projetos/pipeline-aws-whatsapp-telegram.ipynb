{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f582370",
   "metadata": {
    "papermill": {
     "duration": 0.001427,
     "end_time": "2023-11-30T19:55:30.272780",
     "exception": false,
     "start_time": "2023-11-30T19:55:30.271353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"align-items: center; justify-content: space-between;\">\n",
    "   \n",
    "   <h1>Data Pipeline | AWS - Whatsapp - Telegram</h1>\n",
    "   <b> por <a href=\"https://www.linkedin.com/in/fernandohcarneiro/\">Fernando Carneiro</a></b>\n",
    "   <br><br>\n",
    "   <img src=\"https://raw.githubusercontent.com/carneiro-fernando/EBAC/a4a2850a42490d15d266fa584c49fb3a8120fcdb/assets/Images/Projeto_Telegram_pipeline/header_pipeline_aws_chats.drawio.svg\"  align=\"center\" alt=\"data-pipeline\" width=\"auto\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sumário\n",
    "#### 1. [**Introdução**](#intro)  \n",
    "    1.1 Objetivo  \n",
    "    1.2 O que é Pipeline?  \n",
    "    1.3 Pipeline do projeto  \n",
    "#### 2. [**Sistema transacional**](#sistrans)  \n",
    "    2.1 Ingestão de dados  \n",
    "    2.2 O que é uma API?  \n",
    "    2.3 Whatsapp Business API  \n",
    "    2.4 Telegram Botfather  \n",
    "    2.5 Webhook  \n",
    "    2.6 AWS API Gateway  \n",
    "#### 3. [**Sistema analítico**](#sisanal)  \n",
    "    3.1 O que é ETL (Extraction, Transformation, Loading)?  \n",
    "    3.2 Extração (Extraction)    \n",
    "        3.2.1 AWS Lambda  \n",
    "        3.2.2 AWS S3  \n",
    "    3.3 Transformação (Transformation)  \n",
    "    3.4 Carregamento (Loading)    \n",
    "        3.4.1 AWS Event Bridge  \n",
    "#### 4. [**Apresentação**](#apres)  \n",
    "    4.1 AWS Athena  \n",
    "    4.2 Análise de Dados\n",
    "#### 4. [**Conclusão**](#conclu)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objetivo\n",
    "O objetivo deste projeto é demonstrar como é feita a extração de dados provenientes do Telegram e do WhatsApp, transferir esses dados para um ***Datalake***, realizar o processamento dos dados em lote na nuvem e então fazer a análise dos dados tratados. Esses dados fornecem a base para extrair informações valiosas, abrindo possibilidades para aprimorar serviços e explorar oportunidades de monetização.\n",
    "\n",
    "### 1.2 O que é Pipeline?\n",
    "No contexto de ciência de dados, um ***pipeline*** refere-se a uma **sequência de processos automatizados** que são encadeados para realizar tarefas específicas, desde a coleta de dados até a entrega de resultados. Esse conceito é inspirado no campo da engenharia de software, onde um pipeline representa um fluxo contínuo de desenvolvimento e entrega de software.\n",
    "\n",
    "*fonte: https://www.stitchdata.com/resources/what-is-data-pipeline/*\n",
    "\n",
    "### 1.3 Pipeline do projeto\n",
    "O pipeline de dados deste projeto se inicia pela ingestão dos dados dos usuários por meio de API que conectam as fontes com a nuvem da Amazon Web Services(AWS). Na plataforma da AWS os dados são recebidos por uma função Lambda (inserir link) que armazena esses dados de forma organizada por dias no AWS S3. Diariamente um AWS Event Bridge chama um processo em lote no Lambda que transforma os dados brutos extraindo somente o que estamos interessados (data da mensagem, nome e número do contato e a mensagem) e salva de forma organizada no AWS S3. No processo de visualização, tabelas criadas a partir dos arquivos parquet criados no processo anterior, permitem que façamos análises de todo tipo utilizando a linguagem SQL, sendo possível extrair esses dados para um dashboard posteriormente.\n",
    "\n",
    "![Pipeline do projeto](https://raw.githubusercontent.com/carneiro-fernando/EBAC/db382413378537f201bed37cc51b427c83da5a5e/assets/Images/Projeto_Telegram_pipeline/pipeline_aws_chats.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sistrans'></a>\n",
    "## 2. Sistema transacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um sistema transacional é uma estrutura tecnológica e de dados que suporta as transações diárias de uma fonte de dados. Ele é responsável por coletar, registrar e transmitir dados para uma cadeia de processos que tratarão os dados para posterior análise. Em resumo, os sistemas transacionais são projetados para ingerir dados criados diariamente e salvá-los em um banco de dados ou *DataLake*.\n",
    "\n",
    "*fonte: https://insightsoftware.com/encyclopedia/transactional-systems/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Ingestão de dados\n",
    "Neste projeto a ingestão dos dados consiste na captura de mensagens de texto enviadas pelas plataformas Whatsapp e Telegram em tempo real, fornecidas por meio de uma API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 O que é uma API?\n",
    "Uma API, ou Interface de Programação de Aplicações, é um componente de software dentro de um sistema que fornece um mecanismo para invocar uma tarefa em outro sistema. Ela serve como uma ponte que facilita a comunicação e integração entre sistemas ou componentes de software diversos, até de tipos diferentes.\n",
    "\n",
    "*fonte: https://www.3pillarglobal.com/insights/a-simple-api-definition-and-how-apis-work/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Whatsapp Business API\n",
    "É a API da empresa que permite a conexão em escala entre diversos tipos de sistemas e os usuários da plataforma. Neste projeto iremos usá-la para receber as mensagens enviadas para um número de telefone específico configurado. Embora seja possível extrair uma variedade de informações, me concentrei em capturar dados essenciais, como as informações de contato e a mensagem enviada pelo usuário.\n",
    "\n",
    "*Documentação: https://developers.facebook.com/docs/whatsapp/cloud-api/overview*\n",
    "\n",
    "##### 2.3.1 Criação da aplicação\n",
    "Na página *dashboard* do [Meta for developers]('https://developers.facebook.com/') foi criado um aplicativo chamado `chat_to_analysis`.\n",
    "\n",
    "<img src=\"https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/wpp_app_creation.png?raw=true\">\n",
    "\n",
    "Adicionado ao aplicativo criado os serviços necessários para o recebimento de mensagens na plataforma Whatsapp, Whatsapp e Webhooks.\n",
    "\n",
    "<img src=\"https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/wpp_app_integration.png?raw=true\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Telegram Botfather\n",
    "Um chatbot é um programa de computador projetado para simular a interação humana em conversas. Neste projeto iremos usar um chatbot para capturar as mensagens enviadas dentro de um grupo. O BotFather é um bot especial no Telegram que faz a criação e gerenciamento de bots na plataforma. Ele nos permitirá desenvolver e configurar o bot de maneira eficiente e interativa.\n",
    "\n",
    "*Documentação: https://core.telegram.org/bots/features#botfather*\n",
    "\n",
    "##### 2.4.1 Criação do bot\n",
    "No plataforma *web* do *Telegram* foi criado um bot a partir do *Botfather* e dado o nome de `chat_monitor_ro_bot.\n",
    "\n",
    "<img src=\"https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/bot_creation.png.png?raw=true\" alt=\"Bot Creation Image\">\n",
    "\n",
    "Após a criação do bot, criei um grupo ao qual tenho interesse em captar as interações entre os integrantes. \n",
    "\n",
    "<img src='https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/group_creation.png?raw=true'>\n",
    "\n",
    "E foi configurado o bot como administrador, permitindo dessa maneira o bot poderá ouvir a conversa de todos os integrantes deste grupo.\n",
    "\n",
    "<img src='https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/bot_admin.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 AWS API Gateway\n",
    "O primeiro serviço em nuvem na sequência do pipeline, faz parte dos serviços em nuvem da Amazon Web Services (AWS). Este serviço centraliza o gerenciamento das APIs inclusive o recebimento, como no caso deste projeto, em que servirá como porta de entrada para o recebimento do *payload* advindo das plataformas de mensagens. Ele oferece recursos como autenticação, autorização, monitoramento e escalabilidade, simplificando o processo de construção e administração de APIs de forma eficiente na infraestrutura da AWS.\n",
    "\n",
    "*fonte: https://aws.amazon.com/pt/api-gateway/*\n",
    "\n",
    "##### 2.5.1 Criação da API para Whatsapp\n",
    "Na plataforma, foi criada uma nova API com protocolo REST com um método GET e um método POST configurado com integração do tipo proxy com o serviço Lambda.\n",
    "\n",
    "<img src=\"https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/wpp_api_methods.png?raw=true\">\n",
    "\n",
    "##### 2.5.2 Criação da API para Telegram\n",
    "Na plataforma *Telegram*, foi repetido o procedimento e criado uma nova API com protocolo REST porém apenas o método POST, também configurado com integração do tipo proxy com o serviço Lambda.\n",
    "\n",
    "<img src=\"https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/tgm_api_methods.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Webhook\n",
    "Um webhook é uma ferramenta de comunicação automatizada que permite que sistemas online, geralmente APIs, enviem informações em tempo real assim que eventos específicos ocorrem. Com uma abordagem assíncrona baseada em eventos, opera por meio de protocolos HTTP ou HTTPS, fornecendo uma maneira ágil e eficiente de integrar plataformas e serviços online. No escopo deste projeto, o webhook será acionado pelo recebimento de uma nova mensagem, sendo responsável por encaminhar os dados úteis, também chamado de *payload*,  de forma instantânea aos serviços em nuvem.\n",
    "\n",
    "*fonte: https://www.redhat.com/en/topics/automation/what-is-a-webhook*\n",
    "\n",
    "##### 2.6.1 Configuração do Whatsapp\n",
    "Na dashboard *Meta for Developers* foi configurado o *webhook* com a API criada no *AWS API Gateway*, para isso foi passado a URL disponibilizada implantar a API e configurado um script na plataforma Lambda para fazer a verificação. O script que criei pode ser encontrado neste link <LINK PARA O SCRIPT>\n",
    "\n",
    "<img src=\"https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/wpp_webhooks_config.png?raw=true\">\n",
    "\n",
    "Após configurado o *webhook* foi possível selecionar quais os campos de interesse à ser recebidos pelo aplicativo.\n",
    "\n",
    "<img src=\"https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/wpp_webhook_fields.png?raw=true\">\n",
    "\n",
    "##### 2.6.2 Configuração do Telegram\n",
    "O procedimento na plataforma *Telegram* é completamente diferente, nela foi preciso enviar uma requisição GET para acionar o método `setWebhook` e injetando nele o endereço URL adquirido na criação da API do *AWS API Gateway*. Abaixo segue a captura da execução da requisição:\n",
    "\n",
    "<img src=\"https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/webhook_creation.png?raw=true\">\n",
    "\n",
    "Após configurado o *webhook* foi possível verificar seu funcionamento com o método `getWebhookInfo`:\n",
    "\n",
    "<img src=\"https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/webhook_info.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sisanal'></a>\n",
    "## 3. Sistema analítico\n",
    "Esses sistemas apoiam a tomada de decisões, relatórios, consultas e análises. São projetados para lidar com consultas complexas em grandes volumes de dados vindos dos sistemas transacionais, organizam esses dados e os processam de maneira a criar insights úteis. Neste projeto o sistema compreende a retirada dos dados brutos (*raw*) do datalake, a transformação deles em informação e a análise em busca de padrões e insights.\n",
    "\n",
    "*fonte: http://bi-insider.com/posts/types-of-enterprise-data-transactional-analytical-master/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 O que é ETL (Extraction, Transformation, Loading)?\n",
    "É o processo de extrair, limpar e organizar os dados de uma origem para serem carregados, ou armazenados, em um local específico. Essa etapa é crucial para assegurar que os dados estejam em uma forma apropriada e prontos para análise antes de serem empregados em relatórios, visualizações ou em outros procedimentos analíticos.\n",
    "\n",
    " *fonte: https://www.ibm.com/topics/etl*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Extração (Extraction)\n",
    "Envolve a extração, ou coleta, de dados brutos de diferentes fontes, como as APIs neste caso.\n",
    "\n",
    "#### 3.2.1 AWS Lambda\n",
    "O AWS Lambda é um serviço de computação que permite a execução de código sem a necessidade de gerenciar servidores, também chamado de *serverless*. Nela é possível criar funções Lambda, carregar seu código e definir eventos que acionarão a execução da função, sem se preocupar com a escala automática e infraestrutura subjacente. Neste projeto ela se encarregará de executar scripts na linguagem *Python* para manuseio e transformação dos dados.\n",
    "\n",
    "*fonte: https://docs.aws.amazon.com/lambda/latest/dg/welcome.html*\n",
    "\n",
    "#### 3.2.2 AWS S3\n",
    "O Amazon S3, ou Simple Storage Service, é um serviço de armazenamento que permite armazenar e recuperar dados de maneira fácil e escalável. É amplamente utilizado para armazenar arquivos, fazer backup e hospedar sistemas online, proporcionando uma solução eficiente e confiável para necessidades de armazenamento na nuvem. Neste projeto, ele armazenará tanto os dados brutos servindo como *Datalake*, quanto os dados transformados e prontos para análise.\n",
    "\n",
    "*fonte: https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html*\n",
    "\n",
    "##### 3.2.3 Extração Whatsapp\n",
    "Foi desenvolvido um script para a extração dos dados do Whatsapp de acordo com a sua [documentação]('https://developers.facebook.com/docs/graph-api/webhooks/getting-started/webhooks-for-whatsapp?locale=pt_BR') como segue no trecho de código em Python abaixo. Nele é possível notar a verificação que a empresa impõem para estabelecer a conexão e o retorno dos dados na variável `response_body` que contém os dados no formato *JSON*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Desenvolvido por: Fernando Carneiro \n",
    "\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "   \n",
    "# Variáveis de ambiente\n",
    "    BUCKET = os.environ['AWS_S3_BUCKET']\n",
    "    \n",
    "# Declaração de variáveis\n",
    "    tzinfo = timezone(offset=timedelta(hours=-3))\n",
    "    date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n",
    "    timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
    "    filename = f'{timestamp}.json'\n",
    "    \n",
    "# Instanciando client S3\n",
    "    client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        message = json.loads(event[\"body\"])\n",
    "        \n",
    "        with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n",
    "            json.dump(message, fp)\n",
    "        \n",
    "        client.upload_file(f'/tmp/{filename}', BUCKET, f'whatsapp/context_date={date}/{filename}')\n",
    "    \n",
    "    except Exception as exc:\n",
    "        logging.error(msg=exc)\n",
    "        return dict(statusCode=\"500\")\n",
    "    \n",
    "\n",
    "# Verificação do Webhook\n",
    "    VERIFY_TOKEN = os.environ['VERIFY_TOKEN']\n",
    "    \n",
    "    # Checando 'queryStringParameters' para verificar se é um webhook\n",
    "    if event.get('queryStringParameters'):\n",
    "        mode = event['queryStringParameters'].get('hub.mode')\n",
    "        token_sent = event['queryStringParameters'].get('hub.verify_token')\n",
    "        \n",
    "        if mode == 'subscribe' and token_sent == VERIFY_TOKEN:\n",
    "            return {\n",
    "                'statusCode': 200,\n",
    "                'body': event['queryStringParameters']['hub.challenge']\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'statusCode': 403,\n",
    "                'body': 'Nao corresponde'\n",
    "            }\n",
    "\n",
    "    response_body = {\n",
    "        'status': 'success',\n",
    "        'message': 'Success, but queryStringParameters is not present',\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(response_body)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.4 Extração Telegram\n",
    "Abaixo segue o script em Python usado para a extração dos dados do Telegram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import boto3\n",
    "\n",
    "\n",
    "def lambda_handler(event: dict, context: dict) -> dict:\n",
    "\n",
    "  '''\n",
    "  Recebe uma mensagens do Telegram via AWS API Gateway, verifica no\n",
    "  seu conteúdo se foi produzida em um determinado grupo e a escreve, \n",
    "  em seu formato original JSON, em um bucket do AWS S3.\n",
    "  '''\n",
    "\n",
    "  # vars de ambiente\n",
    "\n",
    "  BUCKET = os.environ['AWS_S3_BUCKET']\n",
    "  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n",
    "\n",
    "  # vars lógicas\n",
    "\n",
    "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
    "  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n",
    "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
    "\n",
    "  filename = f'{timestamp}.json'\n",
    "\n",
    "  # código principal\n",
    "\n",
    "  client = boto3.client('s3')\n",
    "  \n",
    "  try:\n",
    "\n",
    "    message = json.loads(event[\"body\"])\n",
    "    chat_id = message[\"message\"][\"chat\"][\"id\"]\n",
    "\n",
    "    if chat_id == TELEGRAM_CHAT_ID:\n",
    "\n",
    "      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n",
    "        json.dump(message, fp)\n",
    "\n",
    "      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n",
    "\n",
    "  except Exception as exc:\n",
    "      logging.error(msg=exc)\n",
    "      return dict(statusCode=\"500\")\n",
    "\n",
    "  else:\n",
    "      return dict(statusCode=\"200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que em ambas as extrações os dados provenientes da *API* em formato *JSON* são direcionados para um endereço na *web* armazenado na variável `BUCKET`. Este é o nome do espaço de armazenamento do serviço *AWS S3* para onde estamos enviando os dados brutos. Na sequência será explanado a etapa seguinte, a de transformação dos dados extraídos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Transformação (Transformation)\n",
    "Nesta etapa, os dados coletados são processados e transformados para atender aos requisitos do destino. Isso inclui limpeza, filtragem, agregação e qualquer manipulação necessária.\n",
    "\n",
    "#### 3.3.1 Transformação Whatsapp (Lambda)\n",
    "Essa foi a etapa ais difícil e demorada de desenvolver, tando em vista tanto os requisitos do sistema de API da empresa, nem sempre com documentação disponível de forma detalhada ou clara, como também quanto à abstração lógica necessária. O script desenvolvido abaixo recebe os dados brutos de um *bucket* e retira dele somente as informações de interesse, devolvendo o dado estruturado no formato de tabela *parquet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Criado por: Fernando Carneiro\n",
    "\n",
    "# Importação de bibliotecas\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Função padrão do AWS Lambda\n",
    "def lambda_handler(event: dict, context: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Função de manipulação do AWS Lambda para processar o evento e o contexto.\n",
    "\n",
    "    Parâmetros:\n",
    "    event (dict): O evento do AWS Lambda.\n",
    "    context (dict): O contexto do AWS Lambda.\n",
    "\n",
    "    Retorna:\n",
    "    bool: Verdadeiro se a operação foi bem-sucedida, Falso caso contrário.\n",
    "    \"\"\"\n",
    "    # Recuperar variáveis de ambiente\n",
    "    RAW_BUCKET = os.environ['AWS_S3_RAW']\n",
    "    ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n",
    "\n",
    "    # Inicializar variáveis lógicas\n",
    "    tzinfo = timezone(offset=timedelta(hours=-3))\n",
    "    date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
    "\n",
    "    table = None\n",
    "    client = boto3.client('s3')\n",
    "\n",
    "    try:\n",
    "        # Listar objetos no bucket raw com o prefixo especificado\n",
    "        response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'whatsapp/context_date={date}')\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        # Percorrer o conteúdo da resposta\n",
    "        for content in response['Contents']:\n",
    "            key = content['Key']\n",
    "            # Baixar o arquivo do bucket raw para um local temporário\n",
    "            client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n",
    "\n",
    "            # Abrir o arquivo baixado e carregar seu conteúdo JSON\n",
    "            with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n",
    "                data = json.load(fp)\n",
    "\n",
    "            # Analisar os dados e anexá-los ao dataframe\n",
    "            if df.empty:\n",
    "                df = parse_data(data=data)\n",
    "            else:\n",
    "                new_df = parse_data(data=data)\n",
    "                df = pd.concat([df, new_df], axis=0, join='outer')\n",
    "\n",
    "        # Converter o dataframe para uma Tabela PyArrow\n",
    "        table = pa.Table.from_pandas(df)\n",
    "        # Escrever a tabela em um arquivo Parquet\n",
    "        pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n",
    "        # Carregar o arquivo Parquet no bucket enriquecido\n",
    "        client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"whatsapp/context_date={date}/{timestamp}.parquet\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as exc:\n",
    "        # Registrar o erro e imprimi-lo\n",
    "        logging.error(msg=exc)\n",
    "        print(f'Erro: {exc}')\n",
    "\n",
    "        return False \n",
    "        \n",
    "# Função para extrair os dados desejados e transformar o dicionário (JSON) em um DataFrame      \n",
    "def parse_data(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analisa os dados fornecidos em um DataFrame do pandas.\n",
    "\n",
    "    Parâmetros:\n",
    "    data (dict): Os dados para analisar.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: Os dados analisados.\n",
    "    \"\"\"\n",
    "    # Inicializa uma lista vazia para armazenar os dados\n",
    "    data_list = []\n",
    "\n",
    "    # Verifica se os dados são um dicionário e contém 'entry'\n",
    "    if isinstance(data, dict) and \"entry\" in data:\n",
    "        # Percorre a lista 'entry'\n",
    "        for i in range(len(data[\"entry\"])):\n",
    "            entry = data[\"entry\"][i]\n",
    "\n",
    "            # Verifica se a entrada é um dicionário e contém 'changes'\n",
    "            if isinstance(entry, dict) and \"changes\" in entry:\n",
    "                # Percorre a lista 'changes'\n",
    "                for j in range(len(entry[\"changes\"])):\n",
    "                    change = entry[\"changes\"][j]\n",
    "\n",
    "                    # Verifica se a alteração é um dicionário e contém 'value'\n",
    "                    if isinstance(change, dict) and \"value\" in change:\n",
    "                        # Obtém o dicionário 'value'\n",
    "                        value = change[\"value\"]\n",
    "\n",
    "                        # Verifica se o valor é um dicionário e contém 'contacts' que deve ser uma lista\n",
    "                        if isinstance(value, dict) and \"contacts\" in value and isinstance(value[\"contacts\"], list):\n",
    "                            # Percorre a lista 'contacts'\n",
    "                            for k in range(len(value[\"contacts\"])):\n",
    "                                # Obtém o dicionário 'contact'\n",
    "                                contact = value[\"contacts\"][k]\n",
    "\n",
    "                                # Verifica se o valor é um dicionário e contém 'messages' que deve ser uma lista\n",
    "                                if isinstance(value, dict) and \"messages\" in value and isinstance(value[\"messages\"], list):\n",
    "                                    # Percorre a lista 'messages'\n",
    "                                    for l in range(len(value[\"messages\"])):\n",
    "                                        # Obtém o dicionário 'message'\n",
    "                                        message = value[\"messages\"][l]\n",
    "\n",
    "                                        # Cria uma linha com as colunas necessárias\n",
    "                                        row = {\n",
    "                                            \"name\": contact[\"profile\"][\"name\"],\n",
    "                                            \"from\": message[\"from\"],\n",
    "                                            \"body\": message[\"text\"][\"body\"],\n",
    "                                            \"timestamp\": message[\"timestamp\"],\n",
    "                                            \"type\": message[\"type\"]\n",
    "                                        }\n",
    "\n",
    "                                        # Anexa a linha à lista de dados\n",
    "                                        data_list.append(row)\n",
    "\n",
    "    # Cria um dataframe a partir da lista de dados\n",
    "    parsed_data = pd.DataFrame(data_list)\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Transformação Telegram (Lambda)\n",
    "O script desenvolvido abaixo de forma similar recebe os dados brutos de um *bucket* e retira dele somente as informações de interesse, devolvendo o dado estruturado no formato de tabela *parquet*. A diferença entre os scripts da plataforma *Whatsapp* e *Telegram* é basicamente a estrutura em que o dado é recebido via *API*, sendo o do *Whatsapp* maior e com mais aninhamento entre itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import boto3\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "def lambda_handler(event: dict, context: dict) -> bool:\n",
    "\n",
    "  '''\n",
    "  Diariamente é executado para compactar as diversas mensagensm, no formato\n",
    "  JSON, do dia anterior, armazenadas no bucket de dados cru, em um único \n",
    "  arquivo no formato PARQUET, armazenando-o no bucket de dados enriquecidos\n",
    "  '''\n",
    "\n",
    "  # vars de ambiente\n",
    "\n",
    "  RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n",
    "  ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n",
    "\n",
    "  # vars lógicas\n",
    "\n",
    "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
    "  date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
    "\n",
    "  # código principal\n",
    "\n",
    "  table = None\n",
    "  client = boto3.client('s3')\n",
    "\n",
    "  try:\n",
    "\n",
    "      response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'telegram/context_date={date}')\n",
    "\n",
    "      for content in response['Contents']:\n",
    "\n",
    "        key = content['Key']\n",
    "        client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n",
    "\n",
    "        with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n",
    "\n",
    "          data = json.load(fp)\n",
    "          data = data[\"message\"]\n",
    "\n",
    "        parsed_data = parse_data(data=data)\n",
    "        iter_table = pa.Table.from_pydict(mapping=parsed_data)\n",
    "\n",
    "        if table:\n",
    "\n",
    "          table = pa.concat_tables([table, iter_table])\n",
    "\n",
    "        else:\n",
    "\n",
    "          table = iter_table\n",
    "          iter_table = None\n",
    "          \n",
    "      pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n",
    "      client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"telegram/context_date={date}/{timestamp}.parquet\")\n",
    "\n",
    "      return True\n",
    "  \n",
    "  except Exception as exc:\n",
    "      logging.error(msg=exc)\n",
    "      return False\n",
    "  \n",
    "def parse_data(data: dict) -> dict:\n",
    "\n",
    "  date = datetime.now().strftime('%Y-%m-%d')\n",
    "  timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "  parsed_data = dict()\n",
    "\n",
    "  for key, value in data.items():\n",
    "\n",
    "      if key == 'from':\n",
    "          for k, v in data[key].items():\n",
    "              if k in ['id', 'is_bot', 'first_name']:\n",
    "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
    "\n",
    "      elif key == 'chat':\n",
    "          for k, v in data[key].items():\n",
    "              if k in ['id', 'type']:\n",
    "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
    "\n",
    "      elif key in ['message_id', 'date', 'text']:\n",
    "          parsed_data[key] = [value]\n",
    "\n",
    "  if not 'text' in parsed_data.keys():\n",
    "    parsed_data['text'] = [None]\n",
    "\n",
    "  return parsed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos os scripts retornam a um *bucket* uma tabela no formato *parquet* organizada com os seguintes dados:\n",
    "\n",
    "* Whatsapp Schema\n",
    "\n",
    "| Column Name | Data Type |\n",
    "|-------------|-----------|\n",
    "| name        | object    |\n",
    "| number      | int64     |\n",
    "| message     | object    |\n",
    "| date        | int64     |\n",
    "| type        | object    |\n",
    "\n",
    "* Telegram Schema\n",
    "\n",
    "| Column Name      | Data Type |\n",
    "|------------------|-----------|\n",
    "| message_id       | int64     |\n",
    "| user_id          | int64     |\n",
    "| user_is_bot      | bool      |\n",
    "| user_first_name  | object    |\n",
    "| chat_id          | int64     |\n",
    "| chat_type        | object    |\n",
    "| date             | int64     |\n",
    "| text             | object    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Carregamento (Loading)\n",
    "\n",
    "#### 3.4 AWS Event Bridge\n",
    "É um serviço que permite a criação de regras baseadas em cronogramas para acionar eventos em horários específicos, facilitando a automação de tarefas recorrentes. Essa funcionalidade é útil para programar a execução de determinadas ações, como a ativação das funções Lambda deste projeto, conforme a agenda predefinida.\n",
    "\n",
    "*fonte: https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-what-is.html*\n",
    "\n",
    "Para este projeto, o *AWS Event Bridge* foi responsável por inicializar o processo de transformação, uma vez ao dia às 00:00h. Ambos os scripts Python de transformação são executados, tanto do Whatsapp quanto do Telegram.\n",
    "\n",
    "![Eventos agendados](https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/schedules.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='apres'></a>\n",
    "## 4. Apresentação\n",
    "Nesta fase os dados são disponibilizados para os usuários finais, como analistas e cientistas de dados, e para sistemas de consulta, como dashboards e motores de consulta. Geralmente, as informações são acessadas por meio de ferramentas de consulta, como *SQL*, sendo esta a principal interface para a maioria dos usuários. Nesse contexto, a etapa de apresentação utiliza o *AWS Athena*, uma ferramenta com motor de consulta *SQL*, simplificando a leitura e visualização dos dados armazenados na camada *ETL* para análises eficazes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 AWS Athena\n",
    "O AWS Athena é um serviço de consulta interativa que permite analisar dados armazenados no Amazon S3 usando SQL padrão. Ele elimina a necessidade de carregar dados para um banco de dados permitindo explorar grandes conjuntos de dados de maneira fácil e flexível, obtendo insights valiosos sem a necessidade de infraestrutura prévia ou complexos processos de gerenciamento de dados. É especialmente útil em cenários de *Big Data* e *Data Lakes* como no nosso caso, proporcionando uma abordagem ágil para análise de dados na nuvem. É o meio escolhido para este projeto, para visualizar e analisar as informações armazenadas.\n",
    "\n",
    "*fonte: https://docs.aws.amazon.com/athena/latest/ug/what-is.html*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f050b",
   "metadata": {},
   "source": [
    "Na etapa de **apresentação**, o `AWS Athena` tem função de entregar o dados através de uma interface SQL para os usuários do sistema analítico. Para o projeto foram criadas duas tabelas, uma para cada plataforma e depois analisados brevemente as informações obtidas. Para a criação das tabelas foi usado a linguagem SQL, veja abaixo alguns exemplos começando pelas queries de criação de ambas as tabelas:\n",
    "\n",
    "Criação da tabela SQL - Whatsapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1697826171.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    CREATE EXTERNAL TABLE `whatsapp`(\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "CREATE EXTERNAL TABLE `whatsapp`(\n",
    "  `name` string, \n",
    "  `number` bigint, \n",
    "  `message` string, \n",
    "  `date` bigint, \n",
    "  `type` string)\n",
    "PARTITIONED BY ( \n",
    "  `context_date` date)\n",
    "ROW FORMAT SERDE \n",
    "  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe' \n",
    "STORED AS INPUTFORMAT \n",
    "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat' \n",
    "OUTPUTFORMAT \n",
    "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\n",
    "LOCATION\n",
    "  's3://<bucket>/whatsapp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109f516",
   "metadata": {},
   "source": [
    "Criação da tabela SQL - Telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a383d",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE EXTERNAL TABLE `telegram`(\n",
    "  `message_id` bigint, \n",
    "  `user_id` bigint, \n",
    "  `user_is_bot` boolean, \n",
    "  `user_first_name` string, \n",
    "  `chat_id` bigint, \n",
    "  `chat_type` string, \n",
    "  `text` string, \n",
    "  `date` bigint)\n",
    "PARTITIONED BY ( \n",
    "  `context_date` date)\n",
    "ROW FORMAT SERDE \n",
    "  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe' \n",
    "STORED AS INPUTFORMAT \n",
    "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat' \n",
    "OUTPUTFORMAT \n",
    "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\n",
    "LOCATION\n",
    "  's3://<bucket>/telegram/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf03b3df",
   "metadata": {},
   "source": [
    "A consulta SQL a seguir foi projetada para validar a criação bem-sucedida de uma das tabelas em nosso banco de dados. Além disso, ela confirma se os dados particionados foram corretamente capturados, armazenados e depois recuperados no serviço S3. Esta verificação é crucial para garantir a integridade dos dados antes de prosseguirmos com qualquer análise adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48676c8",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM \"whatsapp\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b73ae8",
   "metadata": {},
   "source": [
    "O resultado da consulta é exibido na página do serviço *Athena* da seguinte maneira:\n",
    "\n",
    "![Consulta SQL](https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/wpp_sql_querie0.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea0ed0",
   "metadata": {},
   "source": [
    "### 4.2 Análise Exploratória de Dados\n",
    "Nesta seção, aprofundamos a análise dos dados enriquecidos por meio de consultas, buscando entender melhor as nuances e informações presentes. As consultas SQL feitas no serviço *Athena* nos possibilitam a criar gráficos para análise exploratória e extração de insights, com essas conclusões podemos entender melhor o comportamento dos usuários do grupo e, a partir disso, criar estratégias para melhorar a experiência deles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c46908",
   "metadata": {},
   "source": [
    "Utilizando ainda a consulta de teste anterior, as informações consultadas foram visualizadas por meio da plotagem gráfica das colunas de dados consultadas. Abaixo, apresenta-se a quantidade de mensagens por usuário, fornecendo insights sobre os principais contatos na plataforma *WhatsApp*.\n",
    "\n",
    "![Gráfico de Frequência por Usuário](https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/graphs_freq_name.png?raw=true)\n",
    "\n",
    "Observa-se que os usuários mais ativos na plataforma *WhatsApp* são o Daniel e a Fernanda. Com base nessa informação, torna-se viável implementar um tratamento personalizado para cada usuário, priorizando a resposta aos contatos mais frequentes. Além disso, é possível adotar medidas para envolver os usuários que interagem menos, buscando aumentar a participação e fortalecer o relacionamento com esses contatos na plataforma. Essa abordagem personalizada contribui para uma gestão mais eficiente e orientada ao engajamento, promovendo uma experiência mais satisfatória para todos os usuários envolvidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dadc6ee",
   "metadata": {},
   "source": [
    "A seguir, apresentamos a visualização da contagem de repetições para a coluna de conteúdo das mensagens.\n",
    "\n",
    "![Gráfico de Frequência por Conteúdo](https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/graph_freq_msg.png?raw=true)\n",
    "\n",
    "A análise revelou que a mensagem mais comum é \"Bom dia\", indicando que as interações dos usuários nesta plataforma tendem a se iniciar durante o período matutino. Essa percepção oferece insights valiosos para compreender o comportamento dos usuários ao longo do dia, possibilitando estratégias mais alinhadas com os padrões de engajamento observados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, uma consulta SQL realizada para uma análise dos dados enriquecidos da tabela `whatsapp`. Inicialmente, converte o campo de data/hora (`timestamp`) para um formato legível de carimbo de data/hora. Posteriormente, extrai informações como a hora do dia, o dia da semana e o número da semana a partir do carimbo de data/hora. Por fim, agrupa os dados, contabilizando o número de mensagens para cada combinação de hora, dia da semana e número da semana. Isso proporciona um resumo da frequência das mensagens, destacando padrões temporais relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "WITH \n",
    "parsed_date_cte AS (\n",
    "    SELECT \n",
    "        *, \n",
    "        CAST(date_format(from_unixtime(\"date\"),'%Y-%m-%d %H:%i:%s') AS timestamp) AS parsed_date\n",
    "    FROM \"whatsapp\" \n",
    "),\n",
    "hour_week_cte AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        EXTRACT(hour FROM parsed_date) AS hora_do_dia,\n",
    "        EXTRACT(dow FROM parsed_date) AS dia_da_semana,\n",
    "        EXTRACT(week FROM parsed_date) AS semana_do_ano\n",
    "    FROM parsed_date_cte\n",
    ")\n",
    "SELECT\n",
    "    hora_do_dia,\n",
    "    dia_da_semana,\n",
    "    semana_do_ano,\n",
    "    count(1) AS \"qtd_de_mensagens\" \n",
    "FROM hour_week_cte\n",
    "GROUP BY\n",
    "    hora_do_dia,\n",
    "    dia_da_semana,\n",
    "    semana_do_ano\n",
    "ORDER BY\n",
    "    semana_do_ano,\n",
    "    dia_da_semana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado dessa consulta é uma tabela semelhante a abaixo:\n",
    "\n",
    "| hora_do_dia | dia_da_semana | semana_do_ano | qtd_de_mensagens |\n",
    "|-------------------|---------------------|---------------------|----------------|\n",
    "| 15                | 2                   | 46                  | 10              |\n",
    "| 16                | 6                   | 46                  | 13              |\n",
    "| 10                | 5                   | 47                  | 16              |\n",
    "| 12                | 1                   | 47                  | 31              |\n",
    "| 13                | 4                   | 47                  | 13              |\n",
    "| 14                | 5                   | 47                  | 25              |\n",
    "| 10                | 7                   | 47                  | 37              |\n",
    "| 18                | 6                   | 47                  | 13              |\n",
    "| 16                | 1                   | 48                  | 24              |\n",
    "| 23                | 4                   | 48                  | 22              |\n",
    "| 14                | 6                   | 48                  | 28              |\n",
    "| 11                | 3                   | 48                  | 44              |\n",
    "| 14                | 3                   | 48                  | 16              |\n",
    "| 19                | 3                   | 49                  | 38              |\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d410c57f",
   "metadata": {},
   "source": [
    "Cada gráfico atua como uma ferramenta para extrair informações significativas, contribuindo para uma análise mais aprofundada dos padrões e tendências presentes nos dados. Esse processo é essencial para identificar nuances que podem passar despercebidas em análises mais superficiais, melhorando assim a interpretação dos dados. Inicialmente, foi plotado um gráfico de mensagens por hora.\n",
    "\n",
    "![Gráfico de Mensagens por Hora](https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/graph_msgs_hr.png?raw=true)\n",
    "\n",
    "A análise da quantidade de mensagens por hora oferece insights sobre os períodos de maior atividade no grupo. Nota-se que os horários de pico ocorrem às 11 da manhã, ao meio-dia e às 19 horas. Esses momentos coincidem com os horários de refeições, antes do almoço e antes do jantar, indicando uma pausa nas atividades para verificar mensagens. Essa informação valiosa possibilita a adaptação de abordagens mais eficazes para usuários, visando resultados aprimorados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893798c5",
   "metadata": {},
   "source": [
    "\n",
    "![Gráfico de Mensagens por Dia da Semana](https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/graph_msgs_dia_sem.png?raw=true)\n",
    "\n",
    "A análise da quantidade de mensagens por dia da semana revela os dias de maior movimento no grupo. Observa-se que domingo (7) lidera, seguido por segunda-feira (1) e quarta-feira (3). Esses resultados indicam, conforme esperado, uma atividade mais intensa no domingo, um dia de descanso. O sábado, também considerado dia de descanso, apresenta um menor número de mensagens, sugerindo que os usuários possivelmente se envolvem em outras atividades, caracterizando-o como o \"dia de sair à noite\". O aumento nas mensagens na segunda-feira e quarta-feira pode refletir a relutância em retomar o trabalho na primeira semana e a monotonia do meio da semana, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a7df6",
   "metadata": {},
   "source": [
    "![Gráfico de Mensagens por Dia do Ano](https://github.com/carneiro-fernando/EBAC/blob/main/assets/Images/Projeto_Telegram_pipeline/graph_msgs_dia_ano.png?raw=true)\n",
    "\n",
    "A análise da quantidade de mensagens por dia do ano oferece insights sobre os períodos de maior atividade no grupo ao longo do ano. Destaca-se a semana 49, correspondente ao início de dezembro, como o período de maior movimento. Isso sugere que, ao se aproximar o fim do ano, a interação dos usuários com a plataforma de mensagens aumenta significativamente. Essa compreensão temporal é valiosa para ajustar estratégias e alocar recursos de forma mais eficaz durante períodos de maior demanda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb222577",
   "metadata": {},
   "source": [
    "<a id='conclu'></a>\n",
    "## 5. Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6c7bb3",
   "metadata": {},
   "source": [
    "A convergência entre as plataformas WhatsApp e Telegram, análise de dados, e o uso de plataformas em nuvem, como a AWS neste projeto, otimiza de forma expressiva as operações empresariais. Essas plataformas, com interfaces ágeis disponíveis 24 horas por dia, simplificam a interação do cliente. O emprego da AWS intensifica essa interação ao oferecer escalabilidade, flexibilidade e confiabilidade, com ajustes dinâmicos de recursos conforme a demanda.\n",
    "\n",
    "A análise de dados, impulsionada por pipelines na nuvem, torna-se ainda mais eficiente com essa abordagem, proporcionando processamento em grande escala e armazenamento seguro. Isso possibilita a extração de insights detalhados a partir de volumes substanciais de informações geradas pelas interações dos usuários nas plataformas. \n",
    "\n",
    "As vantagens incluem também a redução de custos pela nuvem, eliminando a necessidade de investir em infraestrutura física, e a agilidade na adaptação a mudanças nas demandas operacionais, garantindo eficiência contínua. A segurança não pode ser deixada de lado, especialmente ao lidar com informações do cliente em interações nas plataformas. Plataformas em nuvem, como a AWS, implementam protocolos rigorosos, protegendo dados sensíveis contra ameaças cibernéticas. \n",
    "\n",
    "Em resumo, essa integração proporciona uma abordagem sinérgica que aprimora a experiência do cliente nas plataformas WhatsApp e Telegram, otimiza a eficiência operacional e oferece suporte estratégico para tomada de decisões. A aplicação de um pipeline de análise de dados desempenha um papel fundamental no cenário corporativo, fornecendo recursos para impulsionar inovação e excelência."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.632042,
   "end_time": "2023-11-30T19:55:30.590898",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-30T19:55:27.958856",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
