{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f582370",
   "metadata": {
    "papermill": {
     "duration": 0.001427,
     "end_time": "2023-11-30T19:55:30.272780",
     "exception": false,
     "start_time": "2023-11-30T19:55:30.271353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"align-items: center; justify-content: space-between;\">\n",
    "   <img src=\"\"  align=\"right\" alt=\"Semantix-logo\" width=\"15%\">\n",
    "\n",
    "   <h1>Data Pipeline | AWS - Whatsapp - Telegram</h1>\n",
    "   <b> por <a href=\"https://www.linkedin.com/in/fernandohcarneiro/\">Fernando Carneiro</a> </b>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Sumário\n",
    "1. [**Introdução**](#intro)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objetivo\n",
    "O objetivo deste projeto é demonstrar como é feita a extração de dados provenientes do Telegram e do WhatsApp, transferir esses dados para um ***Datalake***, realizar o processamento dos dados em lote na nuvem e então fazer a análise dos dados tratados. Esses dados fornecem a base para extrair informações valiosas, abrindo possibilidades para aprimorar serviços e explorar oportunidades de monetização.\n",
    "\n",
    "### 1.2 O que é Pipeline?\n",
    "No contexto de ciência de dados, um ***pipeline*** refere-se a uma **sequência de processos automatizados** que são encadeados para realizar tarefas específicas, desde a coleta de dados até a entrega de resultados. Esse conceito é inspirado no campo da engenharia de software, onde um pipeline representa um fluxo contínuo de desenvolvimento e entrega de software.\n",
    "\n",
    "    <Imagem aqui>\n",
    "\n",
    "*fonte: https://www.stitchdata.com/resources/what-is-data-pipeline/*\n",
    "\n",
    "### 1.3 Pipeline do projeto\n",
    "O pipeline de dados deste projeto se inicia pela ingestão dos dados dos usuários por meio de API que conectam as fontes com a nuvem da Amazon Web Services(AWS). Na plataforma da AWS os dados são recebidos por uma função Lambda (inserir link) que armazena esses dados de forma organizada por dias no AWS S3. Diariamente um AWS Event Bridge chama um processo em lote no Lambda que transforma os dados brutos extraindo somente o que estamos interessados (data da mensagem, nome e número do contato e a mensagem) e salva de forma organizada no AWS S3. No processo de visualização, tabelas criadas a partir dos arquivos parquet criados no processo anterior, permitem que façamos análises de todo tipo utilizando a linguagem SQL, sendo possível extrair esses dados para um dashboard posteriormente.\n",
    "\n",
    "<Animação com o Pipeline do projeto>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sistema transacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um sistema transacional é uma estrutura tecnológica e de dados que suporta as transações diárias de uma fonte de dados. Ele é responsável por coletar, registrar e transmitir dados para uma cadeia de processos que tratarão os dados para posterior análise. Em resumo, os sistemas transacionais são projetados para ingerir dados criados diariamente e salvá-los em um banco de dados ou *DataLake*.\n",
    "\n",
    "*fonte: https://insightsoftware.com/encyclopedia/transactional-systems/ *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Ingestão de dados\n",
    "Neste projeto a ingestão dos dados consiste na captura de mensagens de texto enviadas pelas plataformas Whatsapp e Telegram em tempo real, fornecidas por meio de uma API.\n",
    "\n",
    "#### 2.2 O que é uma API?\n",
    "Uma API, ou Interface de Programação de Aplicações, é um componente de software dentro de um sistema que fornece um mecanismo para invocar uma tarefa em outro sistema. Ela serve como uma ponte que facilita a comunicação e integração entre sistemas ou componentes de software diversos, até de tipos diferentes.\n",
    "\n",
    "* fonte: https://www.3pillarglobal.com/insights/a-simple-api-definition-and-how-apis-work/ *\n",
    "\n",
    "#### 2.3 Whatsapp Business API\n",
    "É a API da empresa que permite a conexão em escala entre diversos tipos de sistemas e os usuários da plataforma. Neste projeto iremos usá-la para receber as mensagens enviadas para um número de telefone específico configurado. Embora seja possível extrair uma variedade de informações, me concentrei em capturar dados essenciais, como as informações de contato e a mensagem enviada pelo usuário.\n",
    "\n",
    "* fonte: https://developers.facebook.com/docs/whatsapp/cloud-api/overview *\n",
    "\n",
    "#### 2.4 Telegram Botfather\n",
    "Um chatbot é um programa de computador projetado para simular a interação humana em conversas. Neste projeto iremos usar um chatbot para capturar as mensagens enviadas dentro de um grupo. O BotFather é um bot especial no Telegram que faz a criação e gerenciamento de bots na plataforma. Ele nos permitirá desenvolver e configurar o bot de maneira eficiente e interativa.\n",
    "\n",
    "* fonte: https://core.telegram.org/bots/features#botfather *\n",
    "\n",
    "#### 2.5 Webhook\n",
    "Um webhook é uma ferramenta de comunicação automatizada que permite que sistemas online, geralmente APIs, enviem informações em tempo real assim que eventos específicos ocorrem. Com uma abordagem assíncrona baseada em eventos, opera por meio de protocolos HTTP ou HTTPS, fornecendo uma maneira ágil e eficiente de integrar plataformas e serviços online. No escopo deste projeto, o webhook será acionado pelo recebimento de uma nova mensagem, sendo responsável por encaminhar os dados úteis, também chamado de *payload*,  de forma instantânea aos serviços em nuvem.\n",
    "\n",
    "* fonte: https://www.redhat.com/en/topics/automation/what-is-a-webhook *\n",
    "\n",
    "#### 2.6 AWS API Gateway\n",
    "O primeiro serviço em nuvem na sequência do pipeline, faz parte dos serviços em nuvem da Amazon Web Services (AWS). Este serviço centraliza o gerenciamento das APIs inclusive o recebimento, como no caso deste projeto, em que servirá como porta de entrada para o recebimento do *payload* advindo das plataformas de mensagens. Ele oferece recursos como autenticação, autorização, monitoramento e escalabilidade, simplificando o processo de construção e administração de APIs de forma eficiente na infraestrutura da AWS.\n",
    "\n",
    "* fonte: https://aws.amazon.com/pt/api-gateway/ *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sistema analítico\n",
    "Esses sistemas apoiam a tomada de decisões, relatórios, consultas e análises. São projetados para lidar com consultas complexas em grandes volumes de dados vindos dos sistemas transacionais, organizam esses dados e os processam de maneira a criar insights úteis. Neste projeto o sistema compreende a retirada dos dados brutos (*raw*) do datalake, a transformação deles em informação e a análise em busca de padrões e insights.\n",
    "\n",
    "* fonte: http://bi-insider.com/posts/types-of-enterprise-data-transactional-analytical-master/ *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 O que é ETL (Extraction, Transformation, Loading)?\n",
    "É o processo de extrair, limpar e organizar os dados de uma origem para serem carregados, ou armazenados, em um local específico. Essa etapa é crucial para assegurar que os dados estejam em uma forma apropriada e prontos para análise antes de serem empregados em relatórios, visualizações ou em outros procedimentos analíticos.\n",
    "\n",
    " * fonte: https://www.ibm.com/topics/etl*\n",
    "\n",
    "### 3.2 Extração (Extraction)\n",
    "Envolve a extração, ou coleta, de dados brutos de diferentes fontes, como as APIs neste caso.\n",
    "\n",
    "#### 3.2.1 AWS Lambda\n",
    "O AWS Lambda é um serviço de computação que permite a execução de código sem a necessidade de gerenciar servidores, também chamado de *serverless*. Nela é possível criar funções Lambda, carregar seu código e definir eventos que acionarão a execução da função, sem se preocupar com a escala automática e infraestrutura subjacente. Neste projeto ela se encarregará de executar scripts na linguagem *Python* para manuseio e transformação dos dados.\n",
    "\n",
    "*fonte: https://docs.aws.amazon.com/lambda/latest/dg/welcome.html *\n",
    "\n",
    "#### 3.2.2 AWS S3\n",
    "O Amazon S3, ou Simple Storage Service, é um serviço de armazenamento que permite armazenar e recuperar dados de maneira fácil e escalável. É amplamente utilizado para armazenar arquivos, fazer backup e hospedar sistemas online, proporcionando uma solução eficiente e confiável para necessidades de armazenamento na nuvem. Neste projeto, ele armazenará tanto os dados brutos servindo como *Datalake*, quanto os dados transformados e prontos para análise.\n",
    "\n",
    "* fonte: https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html *\n",
    "\n",
    "### 3.3 Transformação (Transformation)\n",
    "Nesta etapa, os dados coletados são processados e transformados para atender aos requisitos do destino. Isso inclui limpeza, filtragem, agregação e qualquer manipulação necessária.\n",
    "\n",
    "### 3.4 Carregamento (Loading)\n",
    "\n",
    "#### 3.4 AWS Event Bridge\n",
    "É um serviço que permite a criação de regras baseadas em cronogramas para acionar eventos em horários específicos, facilitando a automação de tarefas recorrentes. Essa funcionalidade é útil para programar a execução de determinadas ações, como a ativação das funções Lambda deste projeto, conforme a agenda predefinida.\n",
    "\n",
    "* fonte: https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-what-is.html *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apresentação\n",
    "Nesta fase os dados são disponibilizados para os usuários finais, como analistas e cientistas de dados, e para sistemas de consulta, como dashboards e motores de consulta. Geralmente, as informações são acessadas por meio de ferramentas de consulta, como *SQL*, sendo esta a principal interface para a maioria dos usuários. Nesse contexto, a etapa de apresentação utiliza o *AWS Athena*, uma ferramenta com motor de consulta *SQL*, simplificando a leitura e visualização dos dados armazenados na camada *ETL* para análises eficazes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 AWS Athena\n",
    "O AWS Athena é um serviço de consulta interativa que permite analisar dados armazenados no Amazon S3 usando SQL padrão. Ele elimina a necessidade de carregar dados para um banco de dados permitindo explorar grandes conjuntos de dados de maneira fácil e flexível, obtendo insights valiosos sem a necessidade de infraestrutura prévia ou complexos processos de gerenciamento de dados. É especialmente útil em cenários de big data e Data Lakes, proporcionando uma abordagem ágil para análise de dados na nuvem. É o meio escolhido para este projeto, para visualizar e analisar as informações armazenadas.\n",
    "\n",
    "* fonte: https://docs.aws.amazon.com/athena/latest/ug/what-is.html *"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.632042,
   "end_time": "2023-11-30T19:55:30.590898",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-30T19:55:27.958856",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
