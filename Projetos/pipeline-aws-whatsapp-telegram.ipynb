{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f582370",
   "metadata": {
    "papermill": {
     "duration": 0.001427,
     "end_time": "2023-11-30T19:55:30.272780",
     "exception": false,
     "start_time": "2023-11-30T19:55:30.271353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"align-items: center; justify-content: space-between;\">\n",
    "   <img src=\"\"  align=\"right\" alt=\"Semantix-logo\" width=\"15%\">\n",
    "\n",
    "   <h1>Data Pipeline | AWS - Whatsapp - Telegram</h1>\n",
    "   <b> por <a href=\"https://www.linkedin.com/in/fernandohcarneiro/\">Fernando Carneiro</a> </b>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Sumário\n",
    "1. [**Introdução**](#intro)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objetivo\n",
    "O objetivo deste projeto é demonstrar como é feita a extração de dados provenientes do Telegram e do WhatsApp, transferir esses dados para um ***Datalake***, realizar o processamento dos dados em lote na nuvem e então fazer a análise dos dados tratados. Esses dados fornecem a base para extrair informações valiosas, abrindo possibilidades para aprimorar serviços e explorar oportunidades de monetização.\n",
    "\n",
    "### 1.2 O que é Pipeline?\n",
    "No contexto de ciência de dados, um ***pipeline*** refere-se a uma **sequência de processos automatizados** que são encadeados para realizar tarefas específicas, desde a coleta de dados até a entrega de resultados. Esse conceito é inspirado no campo da engenharia de software, onde um pipeline representa um fluxo contínuo de desenvolvimento e entrega de software.\n",
    "\n",
    "    <Imagem aqui>\n",
    "\n",
    "*fonte: https://www.stitchdata.com/resources/what-is-data-pipeline/*\n",
    "\n",
    "### 1.3 Pipeline do projeto\n",
    "O pipeline de dados deste projeto se inicia pela ingestão dos dados dos usuários por meio de API que conectam as fontes com a nuvem da Amazon Web Services(AWS). Na plataforma da AWS os dados são recebidos por uma função Lambda (inserir link) que armazena esses dados de forma organizada por dias no AWS S3. Diariamente um AWS Event Bridge chama um processo em lote no Lambda que transforma os dados brutos extraindo somente o que estamos interessados (data da mensagem, nome e número do contato e a mensagem) e salva de forma organizada no AWS S3. No processo de visualização, tabelas criadas a partir dos arquivos parquet criados no processo anterior, permitem que façamos análises de todo tipo utilizando a linguagem SQL, sendo possível extrair esses dados para um dashboard posteriormente.\n",
    "\n",
    "<Animação com o Pipeline do projeto>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.632042,
   "end_time": "2023-11-30T19:55:30.590898",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-30T19:55:27.958856",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
